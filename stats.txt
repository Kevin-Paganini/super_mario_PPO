Model saved at iteration 0, steps trained: 128.0, sample results: {'episode_reward_max': 227219.0, 'episode_reward_min': 28347.0, 'episode_reward_mean': 92149.46153846153, 'episode_len_mean': 100.64102564102564, 'episode_media': {}, 'episodes_this_iter': 39, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [147931.0, 126843.0, 120611.0, 41642.0, 42361.0, 28833.0, 152680.0, 167176.0, 31315.0, 85459.0, 124320.0, 28347.0, 116140.0, 35672.0, 127940.0, 200255.0, 120145.0, 109465.0, 40550.0, 227219.0, 163243.0, 167315.0, 33371.0, 151255.0, 30169.0, 39352.0, 157545.0, 43440.0, 118440.0, 46640.0, 31521.0, 28895.0, 33343.0, 38203.0, 137511.0, 115054.0, 33662.0, 113746.0, 36220.0], 'episode_lengths': [158, 141, 117, 60, 60, 39, 157, 159, 42, 91, 126, 38, 130, 49, 133, 197, 120, 111, 57, 207, 166, 174, 46, 156, 41, 57, 162, 63, 141, 67, 43, 39, 46, 53, 138, 124, 46, 121, 50]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.0547541920254797, 'mean_inference_ms': 4.03682854456642, 'mean_action_processing_ms': 0.3606268100864224, 'mean_env_wait_ms': 274.5180278980122, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.015640870118752506, 'StateBufferConnector_ms': 0.01024160629663712, 'ViewRequirementAgentConnector_ms': 0.40293045533009064}}
